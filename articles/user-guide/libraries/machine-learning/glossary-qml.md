---
title: Glossaire de la bibliothèque de Machine Learning Quantum
description: Glossaire des termes du Machine Learning Quantum
author: alexeib2
ms.author: alexeib
ms.date: 2/27/2020
ms.topic: article
uid: microsoft.quantum.libraries.machine-learning.training
no-loc:
- ':::no-loc(Q#):::'
- ':::no-loc($$v):::'
ms.openlocfilehash: 476e93e3737dee6ad8f3a97e8ffbcfb9b0012ee1
ms.sourcegitcommit: 29e0d88a30e4166fa580132124b0eb57e1f0e986
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 10/27/2020
ms.locfileid: "92691513"
---
# <a name="quantum-machine-learning-glossary"></a><span data-ttu-id="3e241-103">Glossaire Machine Learning Quantum</span><span class="sxs-lookup"><span data-stu-id="3e241-103">Quantum Machine Learning glossary</span></span>

<span data-ttu-id="3e241-104">La formation d’un classifieur Quantum centré sur les circuits est un processus avec de nombreuses pièces mobiles qui requièrent la même quantité d’étalonnage par essai et l’erreur de formation de classifieurs traditionnels.</span><span class="sxs-lookup"><span data-stu-id="3e241-104">Training of a circuit-centric quantum classifier is a process with many moving parts that require the same (or slightly larger) amount of calibration by trial and error as training of traditional classifiers.</span></span> <span data-ttu-id="3e241-105">Ici, nous définissons les principaux concepts et ingrédients de ce processus d’apprentissage.</span><span class="sxs-lookup"><span data-stu-id="3e241-105">Here we define the main concepts and ingredients of this training process.</span></span>

## <a name="trainingtesting-schedules"></a><span data-ttu-id="3e241-106">Planifications de formation et de test</span><span class="sxs-lookup"><span data-stu-id="3e241-106">Training/testing schedules</span></span>

<span data-ttu-id="3e241-107">Dans le contexte de l’apprentissage du classifieur, une *planification* décrit un sous-ensemble d’exemples de données dans un jeu d’apprentissage ou de test global.</span><span class="sxs-lookup"><span data-stu-id="3e241-107">In the context of classifier training a *schedule* describes a subset of data samples in an overall training or testing set.</span></span> <span data-ttu-id="3e241-108">Une planification est généralement définie en tant que collection d’index.</span><span class="sxs-lookup"><span data-stu-id="3e241-108">A schedule is usually defined as a collection of sample indices.</span></span>

## <a name="parameterbias-scores"></a><span data-ttu-id="3e241-109">Scores des paramètres/biais</span><span class="sxs-lookup"><span data-stu-id="3e241-109">Parameter/bias scores</span></span>

<span data-ttu-id="3e241-110">Étant donné un vecteur de paramètre candidat et un décalage de classifieur, le *score de validation* est mesuré par rapport à une planification de validation choisie et est exprimé par un certain nombre de classifications incorrectes comptées sur tous les échantillons de la planification.</span><span class="sxs-lookup"><span data-stu-id="3e241-110">Given a candidate parameter vector and a classifier bias, their *validation score* is measured relative to a chosen validation schedule S and is expressed by a number of misclassifications counted over all the samples in the schedule S.</span></span>

## <a name="hyperparameters"></a><span data-ttu-id="3e241-111">Hyperparamètres</span><span class="sxs-lookup"><span data-stu-id="3e241-111">Hyperparameters</span></span>

<span data-ttu-id="3e241-112">Le processus d’apprentissage du modèle est régi par certaines valeurs prédéfinies appelées *hyperparamètres* :</span><span class="sxs-lookup"><span data-stu-id="3e241-112">The model training process is governed by certain pre-set values called *hyperparameters* :</span></span>

### <a name="learning-rate"></a><span data-ttu-id="3e241-113">Taux d’apprentissage</span><span class="sxs-lookup"><span data-stu-id="3e241-113">Learning rate</span></span>

<span data-ttu-id="3e241-114">Il s’agit de l’un des hyperparamètres de clé.</span><span class="sxs-lookup"><span data-stu-id="3e241-114">It is one of the key hyperparameters.</span></span> <span data-ttu-id="3e241-115">Il définit la quantité d’estimations de gradient stochastique actuelle qui a un impact sur la mise à jour des paramètres.</span><span class="sxs-lookup"><span data-stu-id="3e241-115">It defines how much current stochastic gradient estimate impacts the parameter update.</span></span> <span data-ttu-id="3e241-116">La taille du delta de mise à jour des paramètres est proportionnelle au taux d’apprentissage.</span><span class="sxs-lookup"><span data-stu-id="3e241-116">The size of parameter update delta is proportional to the learning rate.</span></span> <span data-ttu-id="3e241-117">Des taux d’apprentissage plus faibles conduisent à une évolution des paramètres plus lente et une convergence plus lente, mais les valeurs excessivement grandes de LR peuvent perturber complètement la convergence, car la descente de dégradé ne s’engage jamais sur une valeur minimale locale particulière.</span><span class="sxs-lookup"><span data-stu-id="3e241-117">Smaller learning rate values lead to slower parameter evolution and slower convergence, but excessively large values of LR may break the convergence altogether as the gradient descent never commits to a particular local minimum.</span></span> <span data-ttu-id="3e241-118">Tandis que le taux d’apprentissage est ajusté de manière adaptative par l’algorithme d’apprentissage dans une certaine mesure, il est important de sélectionner une bonne valeur initiale pour celle-ci.</span><span class="sxs-lookup"><span data-stu-id="3e241-118">While learning rate is adaptively adjusted by the training algorithm to some extent, selecting a good initial value for it is important.</span></span> <span data-ttu-id="3e241-119">Une valeur initiale par défaut normale pour le taux d’apprentissage est 0,1.</span><span class="sxs-lookup"><span data-stu-id="3e241-119">A usual default initial value for learning rate is 0.1.</span></span> <span data-ttu-id="3e241-120">La sélection de la meilleure valeur du taux d’apprentissage est une fine illustration (voir, par exemple, la section 4,3 de Goodfellow et al., « Deep Learning », MIT Press, 2017).</span><span class="sxs-lookup"><span data-stu-id="3e241-120">Selecting the best value of learning rate is a fine art (see, for example, section 4.3 of Goodfellow et al.,"Deep learning", MIT Press, 2017).</span></span>

### <a name="minibatch-size"></a><span data-ttu-id="3e241-121">Taille de minilot</span><span class="sxs-lookup"><span data-stu-id="3e241-121">Minibatch size</span></span>

<span data-ttu-id="3e241-122">Définit le nombre d’échantillons de données utilisés pour une seule estimation du gradient stochastique.</span><span class="sxs-lookup"><span data-stu-id="3e241-122">Defines how many data samples is used for a single estimation of stochastic gradient.</span></span> <span data-ttu-id="3e241-123">Des valeurs plus élevées de taille minilot entraînent généralement une convergence plus robuste et plus monotone, mais peuvent ralentir le processus d’apprentissage, car le coût d’une estimation de dégradé est proportionnel à la taille du minimatch.</span><span class="sxs-lookup"><span data-stu-id="3e241-123">Larger values of minibatch size generally lead to more robust and more monotonic convergence but can potentially slow down the training process, as the cost of any one gradient estimation is proportional to the minimatch size.</span></span> <span data-ttu-id="3e241-124">Une valeur par défaut normale pour la taille de minilot est 10.</span><span class="sxs-lookup"><span data-stu-id="3e241-124">A usual default value for the minibatch size is 10.</span></span>

### <a name="training-epochs-tolerance-gridlocks"></a><span data-ttu-id="3e241-125">Époques de formation, tolérance, gridlocks</span><span class="sxs-lookup"><span data-stu-id="3e241-125">Training epochs, tolerance, gridlocks</span></span>

<span data-ttu-id="3e241-126">« Époque » signifie qu’une passe complète est effectuée sur les données d’apprentissage planifiées.</span><span class="sxs-lookup"><span data-stu-id="3e241-126">"Epoch" means one complete pass through the scheduled training data.</span></span>
<span data-ttu-id="3e241-127">Le nombre maximal d’époques par thread d’apprentissage (voir ci-dessous) doit être limité.</span><span class="sxs-lookup"><span data-stu-id="3e241-127">The maximum number of epochs per a training thread (see below) should be capped.</span></span> <span data-ttu-id="3e241-128">Le thread d’apprentissage est défini pour s’arrêter (avec les meilleurs paramètres candidats connus) lorsque le nombre maximal d’époques a été atteint.</span><span class="sxs-lookup"><span data-stu-id="3e241-128">The training thread is defined to terminate (with the best known candidate parameters) when the maximum number of epochs has been run.</span></span> <span data-ttu-id="3e241-129">Toutefois, cette formation se terminerait plus tôt lorsque la tarification incorrecte du calendrier de validation passe sous une tolérance choisie.</span><span class="sxs-lookup"><span data-stu-id="3e241-129">However such training would terminate earlier when misclassification rate on validation schedule falls below a chosen tolerance.</span></span> <span data-ttu-id="3e241-130">Supposons, par exemple, que la tolérance de la classification incorrecte est de 0,01 (1%); si, dans le cas d’un jeu de validation d’exemples 2000, nous observons moins de 20 incorrections de classifications, le niveau de tolérance a été atteint.</span><span class="sxs-lookup"><span data-stu-id="3e241-130">Suppose, for example, that misclassification tolerance is 0.01 (1%); if on validation set of 2000 samples we are seeing fewer than 20 misclassifications, then the tolerance level has been achieved.</span></span> <span data-ttu-id="3e241-131">Un thread d’apprentissage se termine également prématurément si le score de validation du modèle candidat n’a pas montré d’amélioration par rapport à plusieurs époques consécutives (un Gridlock).</span><span class="sxs-lookup"><span data-stu-id="3e241-131">A training thread also terminates prematurely if the validation score of the candidate model has not shown any improvement over several consecutive epochs (a gridlock).</span></span> <span data-ttu-id="3e241-132">La logique de l’arrêt de Gridlock est actuellement codée en dur.</span><span class="sxs-lookup"><span data-stu-id="3e241-132">The logic for the gridlock termination is currently hardcoded.</span></span>

### <a name="measurements-count"></a><span data-ttu-id="3e241-133">Nombre de mesures</span><span class="sxs-lookup"><span data-stu-id="3e241-133">Measurements count</span></span>

<span data-ttu-id="3e241-134">En estimant les scores de formation/validation et les composants du gradient stochastique sur un appareil quantique, vous devez estimer les chevauchements d’état quantique qui requièrent plusieurs mesures du observables approprié.</span><span class="sxs-lookup"><span data-stu-id="3e241-134">Estimating the training/validation scores and the components of the stochastic gradient on a quantum device amounts to estimating quantum state overlaps that requires multiple measurements of the appropriate observables.</span></span> <span data-ttu-id="3e241-135">Le nombre de mesures doit être mis à l’échelle comme $O (1/\ Epsilon ^ 2) $ où $ \epsilon $ est l’erreur d’estimation souhaitée.</span><span class="sxs-lookup"><span data-stu-id="3e241-135">The number of measurements should scale as $O(1/\epsilon^2)$ where $\epsilon$ is the desired estimation error.</span></span>
<span data-ttu-id="3e241-136">En règle générale, le nombre de mesures initiales peut être approximativement de $1/\ mbox {Tolerance} ^ 2 $ (voir la définition de la tolérance dans le paragraphe précédent).</span><span class="sxs-lookup"><span data-stu-id="3e241-136">As a rule of thumb, the initial measurements count could be approximately $1/\mbox{tolerance}^2$ (see definition of tolerance in the previous paragraph).</span></span> <span data-ttu-id="3e241-137">Vous devez réviser le nombre de mesures vers le haut si la profondeur du dégradé semble trop irrégulière et que la convergence est trop difficile à atteindre.</span><span class="sxs-lookup"><span data-stu-id="3e241-137">One would need to revise the measurement count upward if the gradient descent appears to be too erratic and convergence too hard to achieve.</span></span>

### <a name="training-threads"></a><span data-ttu-id="3e241-138">Threads d’apprentissage</span><span class="sxs-lookup"><span data-stu-id="3e241-138">Training threads</span></span>

<span data-ttu-id="3e241-139">La fonction de vraisemblance, qui est l’utilitaire de formation pour le classifieur, est très rarement convexe, ce qui signifie qu’elle a généralement une multitude de Optima locaux dans l’espace de paramètres qui peuvent varier considérablement selon la qualité.</span><span class="sxs-lookup"><span data-stu-id="3e241-139">The likelihood function which is the training utility for the classifier is very seldom convex, meaning that it usually has a multitude of local optima in the parameter space that may differ significantly by quality.</span></span> <span data-ttu-id="3e241-140">Étant donné que le processus SGD peut converger vers un seul optimal spécifique, il est important d’explorer plusieurs vecteurs de paramètres de démarrage.</span><span class="sxs-lookup"><span data-stu-id="3e241-140">Since the SGD process can converge to only one specific optimum, it is important to explore multiple starting parameter vectors.</span></span> <span data-ttu-id="3e241-141">La pratique courante dans Machine Learning consiste à initialiser de tels vecteurs de démarrage de façon aléatoire.</span><span class="sxs-lookup"><span data-stu-id="3e241-141">Common practice in machine learning is to initialize such starting vectors randomly.</span></span> <span data-ttu-id="3e241-142">L' :::no-loc(Q#)::: API d’apprentissage accepte un tableau arbitraire de tels vecteurs de démarrage, mais le code sous-jacent les explore séquentiellement.</span><span class="sxs-lookup"><span data-stu-id="3e241-142">The :::no-loc(Q#)::: training API accepts an arbitrary array of such starting vectors but the underlying code explores them sequentially.</span></span> <span data-ttu-id="3e241-143">Sur un ordinateur multicœur ou en fait sur une architecture informatique parallèle, il est recommandé d’effectuer plusieurs appels à l' :::no-loc(Q#)::: API de formation en parallèle avec différentes initialisations de paramètres entre les appels.</span><span class="sxs-lookup"><span data-stu-id="3e241-143">On a multicore computer or in fact on any parallel computing architecture it is advisable to perform several calls to :::no-loc(Q#)::: training API in parallel with different parameter initializations across the calls.</span></span>

#### <a name="how-to-modify-the-hyperparameters"></a><span data-ttu-id="3e241-144">Comment modifier les hyperparamètres</span><span class="sxs-lookup"><span data-stu-id="3e241-144">How to modify the hyperparameters</span></span>

<span data-ttu-id="3e241-145">Dans la bibliothèque QML, la meilleure façon de modifier les hyperparamètres consiste à remplacer les valeurs par défaut de l’UDT [`TrainingOptions`](xref:Microsoft.Quantum.MachineLearning.TrainingOptions) .</span><span class="sxs-lookup"><span data-stu-id="3e241-145">In the QML library, the best way to modify the hyperparameters is by overriding the default values of the UDT [`TrainingOptions`](xref:Microsoft.Quantum.MachineLearning.TrainingOptions).</span></span> <span data-ttu-id="3e241-146">Pour ce faire, nous l’appelons avec la fonction [`DefaultTrainingOptions`](xref:Microsoft.Quantum.MachineLearning.DefaultTrainingOptions) et appliquons l’opérateur `w/` pour remplacer les valeurs par défaut.</span><span class="sxs-lookup"><span data-stu-id="3e241-146">To do this we call it with the function [`DefaultTrainingOptions`](xref:Microsoft.Quantum.MachineLearning.DefaultTrainingOptions) and apply the operator `w/` to override the default values.</span></span> <span data-ttu-id="3e241-147">Par exemple, pour utiliser les mesures 100 000 et un taux d’apprentissage de 0,01 :</span><span class="sxs-lookup"><span data-stu-id="3e241-147">For example, to use 100,000 measurements and a learning rate of 0.01:</span></span>

```qsharp
let options = DefaultTrainingOptions()
w/ LearningRate <- 0.01
w/ NMeasurements <- 100000;
```
